{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forest Cover Problem\n",
    "\n",
    "## Objective\n",
    "The study area includes four wilderness areas located in the Roosevelt National Forest of northern Colorado. Each observation is a 30m x 30m patch. You are asked to predict an integer classification for the forest cover type. The seven types are:\n",
    "\n",
    "1 - Spruce/Fir\n",
    "2 - Lodgepole Pine\n",
    "3 - Ponderosa Pine\n",
    "4 - Cottonwood/Willow\n",
    "5 - Aspen\n",
    "6 - Douglas-fir\n",
    "7 - Krummholz\n",
    "\n",
    "The training set (15120 observations) contains both features and the Cover_Type. The test set contains only the features. You must predict the Cover_Type for every row in the test set (565892 observations)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps to complete the project\n",
    "The following steps must be completed to successfully complete this project\n",
    "1. Read in data and clean\n",
    "2. Data visualization to uncover trends\n",
    "3. Feature engineering\n",
    "4. Training algorithm\n",
    "5. Testing algorithm\n",
    "6. Optional - Ensembling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data and cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us start off by importing important data science libraries and reading in the training and testing data. The training and testing data should be combined and shuffled to do some exploratory analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing data handling libraries numpy and pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Importing visualization libraries matplotlib and seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../data/train.csv\")\n",
    "test = pd.read_csv(\"../data/test.csv\")\n",
    "combined = train.append(test, ignore_index = True) # Does not keep index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we go into the data visualization, we need to check if there are any missing values in the training or testing datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking NaN in training dataset\n",
    "train.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking NaN in testing dataset\n",
    "test.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An initial check reveals that there is no missing values in the form of NaN, but sometimes, the database creators may have inputted the missing value as a '0' or another value that does not make sense in context. This will be covered in the data visualization part of the notebook. \n",
    "\n",
    "Furthermore, one-hot encoding should be performed on categorical variables. However, looking at the metadata, it seems that any potential categorical variables has already been one-hot encoded. Let us check whether these encoded variables are categorical. If not, we will factorize them.  (http://pbpython.com/categorical-encoding.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any more data cleaning can only be done with a more indepth look into the data with visualizations.\n",
    "\n",
    "## Exploratory Data Analysis\n",
    "\n",
    "There are a couple of objectives I would like to meet in the EDA:\n",
    "1. Check for the distribution of variables and normalize outliers\n",
    "2. Standardize all variables\n",
    "3. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
